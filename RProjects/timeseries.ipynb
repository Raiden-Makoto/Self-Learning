{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cfcdbe",
   "metadata": {},
   "source": [
    "# Timeseries Forecasting on JENA Climate Dataset in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "845dff1f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘dotty’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/lr/dnbpm8g94tbb2hqq4ksn6lgr0000gn/T//RtmpKEuyZz/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"keras3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05c7b0ce",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'keras3':\n",
      "  method                               from \n",
      "  as.data.frame.keras_training_history keras\n",
      "  plot.keras_training_history          keras\n",
      "  print.keras_training_history         keras\n",
      "  r_to_py.R6ClassGenerator             keras\n",
      "\n",
      "\n",
      "Attaching package: ‘keras3’\n",
      "\n",
      "\n",
      "The following object is masked _by_ ‘.GlobalEnv’:\n",
      "\n",
      "    normalize\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:keras’:\n",
      "\n",
      "    %<-active%, %py_class%, activation_elu, activation_exponential,\n",
      "    activation_gelu, activation_hard_sigmoid, activation_linear,\n",
      "    activation_relu, activation_selu, activation_sigmoid,\n",
      "    activation_softmax, activation_softplus, activation_softsign,\n",
      "    activation_tanh, adapt, application_densenet121,\n",
      "    application_densenet169, application_densenet201,\n",
      "    application_efficientnet_b0, application_efficientnet_b1,\n",
      "    application_efficientnet_b2, application_efficientnet_b3,\n",
      "    application_efficientnet_b4, application_efficientnet_b5,\n",
      "    application_efficientnet_b6, application_efficientnet_b7,\n",
      "    application_inception_resnet_v2, application_inception_v3,\n",
      "    application_mobilenet, application_mobilenet_v2,\n",
      "    application_mobilenet_v3_large, application_mobilenet_v3_small,\n",
      "    application_nasnetlarge, application_nasnetmobile,\n",
      "    application_resnet101, application_resnet101_v2,\n",
      "    application_resnet152, application_resnet152_v2,\n",
      "    application_resnet50, application_resnet50_v2, application_vgg16,\n",
      "    application_vgg19, application_xception, bidirectional,\n",
      "    callback_backup_and_restore, callback_csv_logger,\n",
      "    callback_early_stopping, callback_lambda,\n",
      "    callback_learning_rate_scheduler, callback_model_checkpoint,\n",
      "    callback_reduce_lr_on_plateau, callback_remote_monitor,\n",
      "    callback_tensorboard, clone_model, constraint_maxnorm,\n",
      "    constraint_minmaxnorm, constraint_nonneg, constraint_unitnorm,\n",
      "    count_params, custom_metric, dataset_boston_housing,\n",
      "    dataset_cifar10, dataset_cifar100, dataset_fashion_mnist,\n",
      "    dataset_imdb, dataset_imdb_word_index, dataset_mnist,\n",
      "    dataset_reuters, dataset_reuters_word_index, freeze_weights,\n",
      "    from_config, get_config, get_file, get_layer, get_vocabulary,\n",
      "    get_weights, image_array_save, image_dataset_from_directory,\n",
      "    image_load, image_to_array, imagenet_decode_predictions,\n",
      "    imagenet_preprocess_input, initializer_constant,\n",
      "    initializer_glorot_normal, initializer_glorot_uniform,\n",
      "    initializer_he_normal, initializer_he_uniform,\n",
      "    initializer_identity, initializer_lecun_normal,\n",
      "    initializer_lecun_uniform, initializer_ones,\n",
      "    initializer_orthogonal, initializer_random_normal,\n",
      "    initializer_random_uniform, initializer_truncated_normal,\n",
      "    initializer_variance_scaling, initializer_zeros, install_keras,\n",
      "    keras, keras_model, keras_model_sequential, Layer,\n",
      "    layer_activation, layer_activation_elu,\n",
      "    layer_activation_leaky_relu, layer_activation_parametric_relu,\n",
      "    layer_activation_relu, layer_activation_softmax,\n",
      "    layer_activity_regularization, layer_add, layer_additive_attention,\n",
      "    layer_alpha_dropout, layer_attention, layer_average,\n",
      "    layer_average_pooling_1d, layer_average_pooling_2d,\n",
      "    layer_average_pooling_3d, layer_batch_normalization,\n",
      "    layer_category_encoding, layer_center_crop, layer_concatenate,\n",
      "    layer_conv_1d, layer_conv_1d_transpose, layer_conv_2d,\n",
      "    layer_conv_2d_transpose, layer_conv_3d, layer_conv_3d_transpose,\n",
      "    layer_conv_lstm_1d, layer_conv_lstm_2d, layer_conv_lstm_3d,\n",
      "    layer_cropping_1d, layer_cropping_2d, layer_cropping_3d,\n",
      "    layer_dense, layer_depthwise_conv_1d, layer_depthwise_conv_2d,\n",
      "    layer_discretization, layer_dot, layer_dropout, layer_embedding,\n",
      "    layer_flatten, layer_gaussian_dropout, layer_gaussian_noise,\n",
      "    layer_global_average_pooling_1d, layer_global_average_pooling_2d,\n",
      "    layer_global_average_pooling_3d, layer_global_max_pooling_1d,\n",
      "    layer_global_max_pooling_2d, layer_global_max_pooling_3d,\n",
      "    layer_gru, layer_hashing, layer_input, layer_integer_lookup,\n",
      "    layer_lambda, layer_layer_normalization, layer_lstm, layer_masking,\n",
      "    layer_max_pooling_1d, layer_max_pooling_2d, layer_max_pooling_3d,\n",
      "    layer_maximum, layer_minimum, layer_multi_head_attention,\n",
      "    layer_multiply, layer_normalization, layer_permute,\n",
      "    layer_random_brightness, layer_random_contrast, layer_random_crop,\n",
      "    layer_random_flip, layer_random_rotation, layer_random_translation,\n",
      "    layer_random_zoom, layer_repeat_vector, layer_rescaling,\n",
      "    layer_reshape, layer_resizing, layer_rnn, layer_separable_conv_1d,\n",
      "    layer_separable_conv_2d, layer_simple_rnn,\n",
      "    layer_spatial_dropout_1d, layer_spatial_dropout_2d,\n",
      "    layer_spatial_dropout_3d, layer_string_lookup, layer_subtract,\n",
      "    layer_text_vectorization, layer_unit_normalization,\n",
      "    layer_upsampling_1d, layer_upsampling_2d, layer_upsampling_3d,\n",
      "    layer_zero_padding_1d, layer_zero_padding_2d,\n",
      "    layer_zero_padding_3d, learning_rate_schedule_cosine_decay,\n",
      "    learning_rate_schedule_cosine_decay_restarts,\n",
      "    learning_rate_schedule_exponential_decay,\n",
      "    learning_rate_schedule_inverse_time_decay,\n",
      "    learning_rate_schedule_piecewise_constant_decay,\n",
      "    learning_rate_schedule_polynomial_decay, loss_binary_crossentropy,\n",
      "    loss_categorical_crossentropy, loss_categorical_hinge,\n",
      "    loss_cosine_similarity, loss_hinge, loss_huber, loss_kl_divergence,\n",
      "    loss_mean_absolute_error, loss_mean_absolute_percentage_error,\n",
      "    loss_mean_squared_error, loss_mean_squared_logarithmic_error,\n",
      "    loss_poisson, loss_sparse_categorical_crossentropy,\n",
      "    loss_squared_hinge, mark_active, metric_auc,\n",
      "    metric_binary_accuracy, metric_binary_crossentropy,\n",
      "    metric_categorical_accuracy, metric_categorical_crossentropy,\n",
      "    metric_categorical_hinge, metric_cosine_similarity,\n",
      "    metric_false_negatives, metric_false_positives, metric_hinge,\n",
      "    metric_mean, metric_mean_absolute_error,\n",
      "    metric_mean_absolute_percentage_error, metric_mean_iou,\n",
      "    metric_mean_squared_error, metric_mean_squared_logarithmic_error,\n",
      "    metric_mean_wrapper, metric_poisson, metric_precision,\n",
      "    metric_precision_at_recall, metric_recall,\n",
      "    metric_recall_at_precision, metric_root_mean_squared_error,\n",
      "    metric_sensitivity_at_specificity,\n",
      "    metric_sparse_categorical_accuracy,\n",
      "    metric_sparse_categorical_crossentropy,\n",
      "    metric_sparse_top_k_categorical_accuracy,\n",
      "    metric_specificity_at_sensitivity, metric_squared_hinge,\n",
      "    metric_sum, metric_top_k_categorical_accuracy,\n",
      "    metric_true_negatives, metric_true_positives, new_callback_class,\n",
      "    new_layer_class, new_learning_rate_schedule_class, new_loss_class,\n",
      "    new_metric_class, new_model_class, normalize, optimizer_adadelta,\n",
      "    optimizer_adagrad, optimizer_adam, optimizer_adamax,\n",
      "    optimizer_ftrl, optimizer_nadam, optimizer_rmsprop, optimizer_sgd,\n",
      "    pad_sequences, pop_layer, predict_on_batch, regularizer_l1,\n",
      "    regularizer_l1_l2, regularizer_l2, regularizer_orthogonal,\n",
      "    set_vocabulary, set_weights, shape, test_on_batch,\n",
      "    text_dataset_from_directory, time_distributed,\n",
      "    timeseries_dataset_from_array, to_categorical, train_on_batch,\n",
      "    unfreeze_weights, use_backend, with_custom_object_scope, zip_lists\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"keras3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02531b",
   "metadata": {},
   "source": [
    "## Get the Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c47551c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Date Time'</li><li>'p (mbar)'</li><li>'T (degC)'</li><li>'Tpot (K)'</li><li>'Tdew (degC)'</li><li>'rh (%)'</li><li>'VPmax (mbar)'</li><li>'VPact (mbar)'</li><li>'VPdef (mbar)'</li><li>'sh (g/kg)'</li><li>'H2OC (mmol/mol)'</li><li>'rho (g/m**3)'</li><li>'wv (m/s)'</li><li>'max. wv (m/s)'</li><li>'wd (deg)'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Date Time'\n",
       "\\item 'p (mbar)'\n",
       "\\item 'T (degC)'\n",
       "\\item 'Tpot (K)'\n",
       "\\item 'Tdew (degC)'\n",
       "\\item 'rh (\\%)'\n",
       "\\item 'VPmax (mbar)'\n",
       "\\item 'VPact (mbar)'\n",
       "\\item 'VPdef (mbar)'\n",
       "\\item 'sh (g/kg)'\n",
       "\\item 'H2OC (mmol/mol)'\n",
       "\\item 'rho (g/m**3)'\n",
       "\\item 'wv (m/s)'\n",
       "\\item 'max. wv (m/s)'\n",
       "\\item 'wd (deg)'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Date Time'\n",
       "2. 'p (mbar)'\n",
       "3. 'T (degC)'\n",
       "4. 'Tpot (K)'\n",
       "5. 'Tdew (degC)'\n",
       "6. 'rh (%)'\n",
       "7. 'VPmax (mbar)'\n",
       "8. 'VPact (mbar)'\n",
       "9. 'VPdef (mbar)'\n",
       "10. 'sh (g/kg)'\n",
       "11. 'H2OC (mmol/mol)'\n",
       "12. 'rho (g/m**3)'\n",
       "13. 'wv (m/s)'\n",
       "14. 'max. wv (m/s)'\n",
       "15. 'wd (deg)'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Date Time\"       \"p (mbar)\"        \"T (degC)\"        \"Tpot (K)\"       \n",
       " [5] \"Tdew (degC)\"     \"rh (%)\"          \"VPmax (mbar)\"    \"VPact (mbar)\"   \n",
       " [9] \"VPdef (mbar)\"    \"sh (g/kg)\"       \"H2OC (mmol/mol)\" \"rho (g/m**3)\"   \n",
       "[13] \"wv (m/s)\"        \"max. wv (m/s)\"   \"wd (deg)\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 15</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Date Time</th><th scope=col>p (mbar)</th><th scope=col>T (degC)</th><th scope=col>Tpot (K)</th><th scope=col>Tdew (degC)</th><th scope=col>rh (%)</th><th scope=col>VPmax (mbar)</th><th scope=col>VPact (mbar)</th><th scope=col>VPdef (mbar)</th><th scope=col>sh (g/kg)</th><th scope=col>H2OC (mmol/mol)</th><th scope=col>rho (g/m**3)</th><th scope=col>wv (m/s)</th><th scope=col>max. wv (m/s)</th><th scope=col>wd (deg)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>01.01.2009 00:10:00</td><td>996.52</td><td>-8.02</td><td>265.40</td><td>-8.90</td><td>93.3</td><td>3.33</td><td>3.11</td><td>0.22</td><td>1.94</td><td>3.12</td><td>1307.75</td><td>1.03</td><td>1.75</td><td>152.3</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>01.01.2009 00:20:00</td><td>996.57</td><td>-8.41</td><td>265.01</td><td>-9.28</td><td>93.4</td><td>3.23</td><td>3.02</td><td>0.21</td><td>1.89</td><td>3.03</td><td>1309.80</td><td>0.72</td><td>1.50</td><td>136.1</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>01.01.2009 00:30:00</td><td>996.53</td><td>-8.51</td><td>264.91</td><td>-9.31</td><td>93.9</td><td>3.21</td><td>3.01</td><td>0.20</td><td>1.88</td><td>3.02</td><td>1310.24</td><td>0.19</td><td>0.63</td><td>171.6</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>01.01.2009 00:40:00</td><td>996.51</td><td>-8.31</td><td>265.12</td><td>-9.07</td><td>94.2</td><td>3.26</td><td>3.07</td><td>0.19</td><td>1.92</td><td>3.08</td><td>1309.19</td><td>0.34</td><td>0.50</td><td>198.0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>01.01.2009 00:50:00</td><td>996.51</td><td>-8.27</td><td>265.15</td><td>-9.04</td><td>94.1</td><td>3.27</td><td>3.08</td><td>0.19</td><td>1.92</td><td>3.09</td><td>1309.00</td><td>0.32</td><td>0.63</td><td>214.3</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>01.01.2009 01:00:00</td><td>996.50</td><td>-8.05</td><td>265.38</td><td>-8.78</td><td>94.4</td><td>3.33</td><td>3.14</td><td>0.19</td><td>1.96</td><td>3.15</td><td>1307.86</td><td>0.21</td><td>0.63</td><td>192.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 15\n",
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & Date Time & p (mbar) & T (degC) & Tpot (K) & Tdew (degC) & rh (\\%) & VPmax (mbar) & VPact (mbar) & VPdef (mbar) & sh (g/kg) & H2OC (mmol/mol) & rho (g/m**3) & wv (m/s) & max. wv (m/s) & wd (deg)\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 01.01.2009 00:10:00 & 996.52 & -8.02 & 265.40 & -8.90 & 93.3 & 3.33 & 3.11 & 0.22 & 1.94 & 3.12 & 1307.75 & 1.03 & 1.75 & 152.3\\\\\n",
       "\t2 & 01.01.2009 00:20:00 & 996.57 & -8.41 & 265.01 & -9.28 & 93.4 & 3.23 & 3.02 & 0.21 & 1.89 & 3.03 & 1309.80 & 0.72 & 1.50 & 136.1\\\\\n",
       "\t3 & 01.01.2009 00:30:00 & 996.53 & -8.51 & 264.91 & -9.31 & 93.9 & 3.21 & 3.01 & 0.20 & 1.88 & 3.02 & 1310.24 & 0.19 & 0.63 & 171.6\\\\\n",
       "\t4 & 01.01.2009 00:40:00 & 996.51 & -8.31 & 265.12 & -9.07 & 94.2 & 3.26 & 3.07 & 0.19 & 1.92 & 3.08 & 1309.19 & 0.34 & 0.50 & 198.0\\\\\n",
       "\t5 & 01.01.2009 00:50:00 & 996.51 & -8.27 & 265.15 & -9.04 & 94.1 & 3.27 & 3.08 & 0.19 & 1.92 & 3.09 & 1309.00 & 0.32 & 0.63 & 214.3\\\\\n",
       "\t6 & 01.01.2009 01:00:00 & 996.50 & -8.05 & 265.38 & -8.78 & 94.4 & 3.33 & 3.14 & 0.19 & 1.96 & 3.15 & 1307.86 & 0.21 & 0.63 & 192.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 15\n",
       "\n",
       "| <!--/--> | Date Time &lt;chr&gt; | p (mbar) &lt;dbl&gt; | T (degC) &lt;dbl&gt; | Tpot (K) &lt;dbl&gt; | Tdew (degC) &lt;dbl&gt; | rh (%) &lt;dbl&gt; | VPmax (mbar) &lt;dbl&gt; | VPact (mbar) &lt;dbl&gt; | VPdef (mbar) &lt;dbl&gt; | sh (g/kg) &lt;dbl&gt; | H2OC (mmol/mol) &lt;dbl&gt; | rho (g/m**3) &lt;dbl&gt; | wv (m/s) &lt;dbl&gt; | max. wv (m/s) &lt;dbl&gt; | wd (deg) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 01.01.2009 00:10:00 | 996.52 | -8.02 | 265.40 | -8.90 | 93.3 | 3.33 | 3.11 | 0.22 | 1.94 | 3.12 | 1307.75 | 1.03 | 1.75 | 152.3 |\n",
       "| 2 | 01.01.2009 00:20:00 | 996.57 | -8.41 | 265.01 | -9.28 | 93.4 | 3.23 | 3.02 | 0.21 | 1.89 | 3.03 | 1309.80 | 0.72 | 1.50 | 136.1 |\n",
       "| 3 | 01.01.2009 00:30:00 | 996.53 | -8.51 | 264.91 | -9.31 | 93.9 | 3.21 | 3.01 | 0.20 | 1.88 | 3.02 | 1310.24 | 0.19 | 0.63 | 171.6 |\n",
       "| 4 | 01.01.2009 00:40:00 | 996.51 | -8.31 | 265.12 | -9.07 | 94.2 | 3.26 | 3.07 | 0.19 | 1.92 | 3.08 | 1309.19 | 0.34 | 0.50 | 198.0 |\n",
       "| 5 | 01.01.2009 00:50:00 | 996.51 | -8.27 | 265.15 | -9.04 | 94.1 | 3.27 | 3.08 | 0.19 | 1.92 | 3.09 | 1309.00 | 0.32 | 0.63 | 214.3 |\n",
       "| 6 | 01.01.2009 01:00:00 | 996.50 | -8.05 | 265.38 | -8.78 | 94.4 | 3.33 | 3.14 | 0.19 | 1.96 | 3.15 | 1307.86 | 0.21 | 0.63 | 192.7 |\n",
       "\n"
      ],
      "text/plain": [
       "  Date Time           p (mbar) T (degC) Tpot (K) Tdew (degC) rh (%)\n",
       "1 01.01.2009 00:10:00 996.52   -8.02    265.40   -8.90       93.3  \n",
       "2 01.01.2009 00:20:00 996.57   -8.41    265.01   -9.28       93.4  \n",
       "3 01.01.2009 00:30:00 996.53   -8.51    264.91   -9.31       93.9  \n",
       "4 01.01.2009 00:40:00 996.51   -8.31    265.12   -9.07       94.2  \n",
       "5 01.01.2009 00:50:00 996.51   -8.27    265.15   -9.04       94.1  \n",
       "6 01.01.2009 01:00:00 996.50   -8.05    265.38   -8.78       94.4  \n",
       "  VPmax (mbar) VPact (mbar) VPdef (mbar) sh (g/kg) H2OC (mmol/mol) rho (g/m**3)\n",
       "1 3.33         3.11         0.22         1.94      3.12            1307.75     \n",
       "2 3.23         3.02         0.21         1.89      3.03            1309.80     \n",
       "3 3.21         3.01         0.20         1.88      3.02            1310.24     \n",
       "4 3.26         3.07         0.19         1.92      3.08            1309.19     \n",
       "5 3.27         3.08         0.19         1.92      3.09            1309.00     \n",
       "6 3.33         3.14         0.19         1.96      3.15            1307.86     \n",
       "  wv (m/s) max. wv (m/s) wd (deg)\n",
       "1 1.03     1.75          152.3   \n",
       "2 0.72     1.50          136.1   \n",
       "3 0.19     0.63          171.6   \n",
       "4 0.34     0.50          198.0   \n",
       "5 0.32     0.63          214.3   \n",
       "6 0.21     0.63          192.7   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- read.csv(\"jena_climate_2009_2016.csv\", check.names = FALSE)\n",
    "# Check the actual column names\n",
    "colnames(df)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b808e749",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "step <- 6\n",
    "past <- 720\n",
    "future <- 72\n",
    "learning_rate <- 0.001\n",
    "batch_size <- 256\n",
    "epochs <- 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd85655",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "split_fraction <- 0.715\n",
    "train_split <- floor(split_fraction * nrow(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7110e0e2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "start <- past + future\n",
    "end <- start + train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea86955e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data <- df[1:train_split-1, ]\n",
    "val_data <- df[train_split:nrow(df), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "126b16ca",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select first 7 columns from train_data (columns 1-7 in R)\n",
    "x_train <- as.matrix(train_data[, 1:7])\n",
    "\n",
    "# Select rows from start to end, and column 2 (index 1 in Python, but R is 1-indexed)\n",
    "# Note: Python's iloc[start:end] is exclusive of end, so in R we use (start+1):end\n",
    "y_train <- df[start:end-1, 2]\n",
    "\n",
    "# Calculate sequence length\n",
    "sequence_length <- as.integer(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac729634",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading uv...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_train = keras3::timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = step,\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65aa0c44",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# x_end should be number of rows, not columns\n",
    "x_end <- nrow(val_data) - past - future\n",
    "label_start <- train_split + past + future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a21dd705",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select rows 1 to x_end, and first 7 columns from val_data\n",
    "x_val <- as.matrix(val_data[1:x_end, 1:7])\n",
    "\n",
    "# Select rows from label_start to end, and column 2 (index 1 in Python)\n",
    "y_val <- df[label_start:nrow(df), 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14c28695",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset_val = keras3::timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = step,\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38078f45",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: 256 x 120 x 7 \n",
      "Target shape: 256 \n"
     ]
    }
   ],
   "source": [
    "# Get the first batch from the dataset\n",
    "# In R/keras3, we use as_iterator() and iter_next()\n",
    "iter <- as_iterator(dataset_train)\n",
    "batch <- iter_next(iter)\n",
    "inputs <- batch[[1]]\n",
    "targets <- batch[[2]]\n",
    "\n",
    "# Print shapes (dimensions in R)\n",
    "cat(\"Input shape:\", paste(dim(inputs), collapse = \" x \"), \"\\n\")\n",
    "cat(\"Target shape:\", paste(dim(targets), collapse = \" x \"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9140d14",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
